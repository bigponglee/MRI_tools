{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_CNN(i_chan,\n",
    "          o_chan,\n",
    "          n_layers = 1,\n",
    "          n_chan = 64,\n",
    "          kernel_size = 3,\n",
    "          pad = 1,\n",
    "          stride = 1,\n",
    "          dilation = 1,\n",
    "          bias = True,\n",
    "          bn = True,\n",
    "          activation = nn.Tanh()\n",
    "          ):\n",
    "    # params prep\n",
    "    if isinstance(n_chan,list):\n",
    "        if len(n_chan) == 1:\n",
    "            n_chan = n_chan * (n_layers - 1)\n",
    "    elif isinstance(n_chan,int):\n",
    "        n_chan = [n_chan] * (n_layers - 1)        \n",
    "    \n",
    "    # first layer\n",
    "    cnn3d = [];\n",
    "    if n_layers == 1:\n",
    "        layer_1 = nn.Conv3d(i_chan,o_chan,kernel_size = kernel_size,stride = stride,\n",
    "                      bias = bias, dilation = dilation, padding = pad)\n",
    "        cnn3d.append(layer_1)\n",
    "        if bn :\n",
    "            cnn3d.append(nn.BatchNorm3d(o_chan))\n",
    "        cnn3d.append(activation)\n",
    "        return nn.Sequential(*cnn3d)\n",
    "    else:\n",
    "        layer_1 = nn.Conv3d(i_chan,n_chan[0],kernel_size = kernel_size,stride = stride,\n",
    "                      bias = bias, dilation = dilation, padding = pad)\n",
    "        cnn3d.append(layer_1)\n",
    "        if bn :\n",
    "            cnn3d.append(nn.BatchNorm3d(n_chan))\n",
    "        cnn3d.append(activation)\n",
    "            \n",
    "    # mid layers\n",
    "\n",
    "    for i in range(n_layers-2):\n",
    "        layer_2 = nn.Conv3d(n_chan[i],n_chan[i+1],kernel_size = kernel_size,stride = stride,\n",
    "                  bias = bias, dilation = dilation, padding = pad)\n",
    "        cnn3d.append(layer_2)\n",
    "        if bn :\n",
    "            cnn3d.append(nn.BatchNorm3d(n_chan[i+1]))\n",
    "        cnn3d.append(activation)\n",
    "            \n",
    "    # final layer\n",
    "    layer_3 = nn.Conv3d(n_chan[-1],o_chan,kernel_size = kernel_size,stride = stride,\n",
    "                      bias = bias, dilation = dilation, padding = pad)\n",
    "    cnn3d.append(layer_3)\n",
    "    if bn :\n",
    "        cnn3d.append(nn.BatchNorm3d(o_chan))\n",
    "    cnn3d.append(activation)    \n",
    "    \n",
    "    return nn.Sequential(*cnn3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1,20,5)\n",
    "        self.conv1_p = nn.Conv3d(1,20,5)\n",
    "        self.norm1 = nn.BatchNorm3d(20)\n",
    "        self.conv2 = nn.Conv3d(20,40,5)\n",
    "        self.norm2 = nn.BatchNorm3d(40)\n",
    "        self.conv3 = nn.Conv3d(40,20,3)\n",
    "        self.norm3 = nn.BatchNorm3d(20)\n",
    "        self.conv4 = nn.Conv3d(20,1,3)\n",
    "        self.norm4 = nn.BatchNorm3d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = F.tanh(self.norm1(self.conv1(x)))\n",
    "        out2 = F.tanhshrink(self.norm1(self.conv1_p(x)))\n",
    "        out = out1 + out2\n",
    "        out = F.tanhshrink(self.norm2(self.conv2(out)))\n",
    "        out = F.tanhshrink(self.norm3(self.conv3(out)))\n",
    "        out = F.tanhshrink(self.norm4(self.conv4(out)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 15, 15, 15)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FFT import fft\n",
    "\n",
    "Phase = np.random.randn(15,15,15)\n",
    "A = fft.fft(shape=1,axes=(2,3,4))\n",
    "field_of_view = Phase.shape\n",
    "yy, xx, zz = np.meshgrid(np.arange(0, Phase.shape[1]),\n",
    "                         np.arange(0, Phase.shape[0]),\n",
    "                         np.arange(0, Phase.shape[2]))\n",
    "xx, yy, zz = ((xx - np.round((Phase.shape[0])/2)) / field_of_view[0],\n",
    "              (yy - np.round((Phase.shape[1])/2)) / field_of_view[1],\n",
    "              (zz - np.round((Phase.shape[2])/2)) / field_of_view[2])\n",
    "k2 = xx**2 + yy**2 + zz**2 + np.spacing(1)\n",
    "k2 = np.square(xx) + np.square(yy) + np.square(zz)+ np.spacing(1)\n",
    "k2 = k2[None,None,:]\n",
    "ik2 = 1/k2\n",
    "k2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1.0262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1.0308\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9757\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1.0023\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9123\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9464\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9492\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9148\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8707\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8676\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8405\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8767\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.9198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8522\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8970\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7877\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7949\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7741\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7826\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7715\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7203\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7296\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7703\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7845\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7326\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.8117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7125\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6870\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7115\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6686\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.7415\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6803\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6521\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6885\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6860\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5973\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5845\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5608\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5756\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.6316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5073\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5855\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5497\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5451\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5090\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5301\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5317\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5599\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5051\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4929\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5054\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4700\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4679\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5017\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4050\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4757\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4769\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5062\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4227\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4340\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4415\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4335\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4026\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4223\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4170\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4288\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3974\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3712\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4361\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4024\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4119\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3996\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4525\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = Net_cnn()\n",
    "Iter = 100\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "criteria = nn.MSELoss()\n",
    "\n",
    "for _ in range(Iter):\n",
    "    Phase = np.random.randn(30,1,15,15,15)\n",
    "    LP = A.IFT(k2*A.FT(Phase)).real\n",
    "    data, target = Variable(torch.FloatTensor(LP)), Variable(torch.FloatTensor(Phase[:,:,6:-6,6:-6,6:-6]))\n",
    "    output = net(data)\n",
    "    loss = criteria(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import convolve2d, correlate2d\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class ScipyConv2dFunction(Function):\n",
    "\n",
    "    def forward(self, input, filter):\n",
    "        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n",
    "        self.save_for_backward(input, filter)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, filter = self.saved_tensors\n",
    "        grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full')\n",
    "        grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid')\n",
    "        return torch.FloatTensor(grad_input), torch.FloatTensor(grad_filter)\n",
    "\n",
    "\n",
    "class ScipyConv2d(Module):\n",
    "\n",
    "    def __init__(self, kh, kw):\n",
    "        super(ScipyConv2d, self).__init__()\n",
    "        self.filter = Parameter(torch.randn(kh, kw))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return ScipyConv2dFunction()(input, self.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = range(5)\n",
    "p[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import NUFFT\n",
    "from NUFFT import kb128\n",
    "\n",
    "# kernel & grid def\n",
    "width = 3\n",
    "J_c = (J+1)//2\n",
    "grid_r = np.array([[-64,64],[-64,64],[-64,64]])\n",
    "\n",
    "kb_kernel = kb128.kb128\n",
    "kb_kernel = np.array(kb_kernel[0:J])\n",
    "traj = np.repeat(np.array([[1,2,3,4,5]]),3,axis=0)\n",
    "traj = np.reshape(traj,[3,-1])\n",
    "samples = traj.shape[1]\n",
    "\n",
    "kx = traj[0,:]\n",
    "ky = traj[1,:]\n",
    "kz = traj[2,:]\n",
    "wx_t = kx - np.floor(kx)\n",
    "wy_t = ky - np.floor(ky)\n",
    "wz_t = kz - np.floor(kz)\n",
    "\n",
    "w = np.zeros([3,traj.shape[1]],width)\n",
    "def KB_3d(grid, kb_table,width):\n",
    "    # grid[3,N] kb_table[128]\n",
    "    # low accuracy\n",
    "    k\n",
    "    \n",
    "\n",
    "for i in range(samples):\n",
    "    ind_x = np.array([np.round(np.maximum(kx[i]-width,grid_r[0,0])):np.floor(np.minimum(kx[i]+width,grid_r[0,1]))])\n",
    "    ind_y = np.array([np.round(np.maximum(ky[i]-width,grid_r[1,0])):np.floor(np.minimum(ky[i]+width,grid_r[1,1]))])\n",
    "    ind_z = np.array([np.round(np.maximum(kz[i]-width,grid_r[2,0])):np.floor(np.minimum(kz[i]+width,grid_r[2,1]))])\n",
    "    kgrid_y,kgrid_x,kgrid_z = np.meshgrid(ind_y,ind_x,ind_z)\n",
    "    kgrid = np.concatenate(1,kgrid_x.flatten(),kgrid_y.flatten(),kgrid_z.flatten())\n",
    "    weight = KB_3d(\n",
    "    kernel = value[kgrid_x.reshape(-1),kgrid_y.reshape(-1),kgrid_z.reshape(-1)]\n",
    "    K_kernel = grid_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = 5\n",
    "t = np.array([[0,1,1],[2,4,5]])\n",
    "np.round(1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
