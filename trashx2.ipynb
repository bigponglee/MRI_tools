{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuchengzhu/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/xuchengzhu/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', './data',\n",
    "    \"\"\"Directory of stored data.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size',1,\n",
    "    \"\"\"Size of batch\"\"\")               \n",
    "tf.app.flags.DEFINE_integer('patch_size',128,\n",
    "    \"\"\"Size of a data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('patch_layer',128,\n",
    "    \"\"\"Number of layers in data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('epochs',2000,\n",
    "    \"\"\"Number of epochs for training\"\"\")\n",
    "tf.app.flags.DEFINE_string('log_dir', './tmp/log',\n",
    "    \"\"\"Directory where to write training and testing event logs \"\"\")\n",
    "tf.app.flags.DEFINE_float('init_learning_rate',0.0001,\n",
    "    \"\"\"Initial learning rate\"\"\")\n",
    "tf.app.flags.DEFINE_float('decay_factor',0.01,\n",
    "    \"\"\"Exponential decay learning rate factor\"\"\")\n",
    "tf.app.flags.DEFINE_integer('decay_steps',100,\n",
    "    \"\"\"Number of epoch before applying one learning rate decay\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step',10,\n",
    "    \"\"\"Display and logging interval (train steps)\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_interval',1,\n",
    "    \"\"\"Checkpoint save interval (epochs)\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './tmp/ckpt',\n",
    "    \"\"\"Directory where to write checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_dir','./tmp/model',\n",
    "    \"\"\"Directory to save model\"\"\")\n",
    "tf.app.flags.DEFINE_bool('restore_training',True,\n",
    "    \"\"\"Restore training from last checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_float('drop_ratio',0.9,\n",
    "    \"\"\"Probability to drop a cropped area if the label is empty. All empty patches will be droped for 0 and accept all cropped patches if set to 1\"\"\")\n",
    "tf.app.flags.DEFINE_integer('min_pixel',10,\n",
    "    \"\"\"Minimum non-zero pixels in the cropped label\"\"\")\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size',5,\n",
    "    \"\"\"Number of elements used in shuffle buffer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 2d basic network structure\n",
    "# tensorflow app flags\n",
    "\n",
    "def init_uniform_dist_2d(shape):\n",
    "    with tf.variable_scope('uniform_dist_initializer'):\n",
    "        denominator = tf.cast((tf.reduce_prod(shape[:2]) * tf.reduce_sum(shape[2:])), tf.float32)\n",
    "        lim = tf.sqrt(6. / denominator)\n",
    "        return tf.random_uniform(shape, minval=-lim, maxval=lim)\n",
    "\n",
    "def init_uniform_dist(shape):\n",
    "    with tf.variable_scope('uniform_dist_initializer'):\n",
    "        denominator = tf.cast((tf.reduce_prod(shape)), tf.float32)\n",
    "        lim = tf.sqrt(6. / denominator)\n",
    "        return tf.random_uniform(shape, minval=-lim, maxval=lim)    \n",
    "    \n",
    "def convolution_2d(layer_input, filter, strides, padding='VALID'):\n",
    "    assert len(filter) == 4  # [filter_height, filter_width, in_channels, out_channels]\n",
    "    assert len(strides) == 4  # must match input dimensions [batch, in_height, in_width, in_channels]\n",
    "    assert padding in ['VALID', 'SAME']\n",
    "\n",
    "    w = tf.Variable(initial_value=init_uniform_dist_2d(shape=filter), name='weights')\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[filter[-1]]), name='biases')\n",
    "\n",
    "    return tf.nn.conv2d(layer_input, w, strides, padding) + b\n",
    "\n",
    "def convolution_block_2d(layer_input, n_channels, out_channel,num_convolutions=1):\n",
    "    x = layer_input\n",
    "    for i in range(num_convolutions - 1):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution_2d(x, [5, 5, n_channels, n_channels], [1, 1, 1, 1])\n",
    "            x = tf.nn.relu(x)\n",
    "    x = convolution_2d(x, [5, 5, n_channels, out_channel], [1, 1, 1, 1])\n",
    "    x = x\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def fc_2d(layer_input, in_channel, out_channel):\n",
    "    x = tf.reshape(layer_input,[-1,in_channel])\n",
    "    w = tf.Variable(initial_value=init_uniform_dist([in_channel,out_channel]), name='weights')# shape unknown issue\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[out_channel]), name='biases')\n",
    "    return tf.nn.relu(tf.matmul(x,w)+b)\n",
    "    \n",
    "def readout_2d(layer_input, in_channel, out_channel):\n",
    "    x = tf.reshape(layer_input,[-1,in_channel])\n",
    "    w = tf.Variable(initial_value=init_uniform_dist([in_channel,out_channel]), name='weights')# shape unknown issue\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[out_channel]), name='biases')\n",
    "    return tf.matmul(x,w)+b\n",
    "    \n",
    "def Net(input,shape, n_channel=16, out_channel=10):\n",
    "    x = tf.reshape(input,[-1,shape[0],shape[1]])\n",
    "    x = tf.tile(x[:,:,:,None],[1,1,1,n_channel])\n",
    "    \n",
    "    N = 0\n",
    "    for i in range(N):\n",
    "        with tf.variable_scope('conv_net_'+str(i)):\n",
    "            x = convolution_block_2d(x,n_channel*(i+1),n_channel*(i+2))\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x,[-1,(shape[0]-4*N)*(shape[1]-4*N)*(N+1)*n_channel])\n",
    "    with tf.variable_scope('fc_0'):\n",
    "        x = fc_2d(x, (shape[0]-4*N)*(shape[1]-4*N)*(N+1)*n_channel, 64)\n",
    "        \n",
    "    with tf.variable_scope('readout'):\n",
    "        x = readout_2d(x, 64, out_channel)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    shape = [28,28]\n",
    "    x = tf.placeholder(tf.float32, [None,28*28])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    y = Net(x,shape)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cross_entropy)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for iter in range(10):\n",
    "        for i in range(2000):\n",
    "            batch = mnist.train.next_batch(50)\n",
    "            sess.run(train_step,feed_dict={x: batch[0], y_: batch[1]})\n",
    "            \n",
    "            if i % 200 is 0:\n",
    "                loss = sess.run(cross_entropy,feed_dict={x: batch[0], y_: batch[1]})\n",
    "                print(\"loss function:%g\"%loss)\n",
    "                print(\"Accuracy:%g\"%sess.run(accuracy,feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 16)\n",
      "WARNING:tensorflow:From <ipython-input-3-de99eca4373c>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "loss function:1.71648\n",
      "Accuracy:0.1856\n",
      "loss function:0.222467\n",
      "Accuracy:0.915\n",
      "loss function:0.227311\n",
      "Accuracy:0.9233\n",
      "loss function:0.264777\n",
      "Accuracy:0.9397\n",
      "loss function:0.156363\n",
      "Accuracy:0.9562\n",
      "loss function:0.0723573\n",
      "Accuracy:0.9581\n",
      "loss function:0.109498\n",
      "Accuracy:0.9609\n",
      "loss function:0.0147846\n",
      "Accuracy:0.9607\n",
      "loss function:0.0936627\n",
      "Accuracy:0.9612\n",
      "loss function:0.104914\n",
      "Accuracy:0.9651\n",
      "loss function:0.255487\n",
      "Accuracy:0.9627\n",
      "loss function:0.0976764\n",
      "Accuracy:0.9639\n",
      "loss function:0.0151109\n",
      "Accuracy:0.9666\n",
      "loss function:0.0146838\n",
      "Accuracy:0.9611\n",
      "loss function:0.110932\n",
      "Accuracy:0.9653\n",
      "loss function:0.175423\n",
      "Accuracy:0.9698\n",
      "loss function:0.0811564\n",
      "Accuracy:0.9667\n",
      "loss function:0.0855653\n",
      "Accuracy:0.9709\n",
      "loss function:0.00971404\n",
      "Accuracy:0.9646\n",
      "loss function:0.0352633\n",
      "Accuracy:0.9689\n",
      "loss function:0.0399028\n",
      "Accuracy:0.9653\n",
      "loss function:0.026935\n",
      "Accuracy:0.9727\n",
      "loss function:0.0539526\n",
      "Accuracy:0.9687\n",
      "loss function:0.0323939\n",
      "Accuracy:0.9723\n",
      "loss function:0.0553914\n",
      "Accuracy:0.972\n",
      "loss function:0.00538081\n",
      "Accuracy:0.9723\n",
      "loss function:0.0231264\n",
      "Accuracy:0.9696\n",
      "loss function:0.0147163\n",
      "Accuracy:0.9688\n",
      "loss function:0.02351\n",
      "Accuracy:0.9694\n",
      "loss function:0.0715491\n",
      "Accuracy:0.9719\n",
      "loss function:0.0107477\n",
      "Accuracy:0.9705\n",
      "loss function:0.0049278\n",
      "Accuracy:0.9701\n",
      "loss function:0.0784298\n",
      "Accuracy:0.9661\n",
      "loss function:0.0386566\n",
      "Accuracy:0.9717\n",
      "loss function:0.00687135\n",
      "Accuracy:0.9721\n",
      "loss function:0.0261778\n",
      "Accuracy:0.9686\n",
      "loss function:0.0741692\n",
      "Accuracy:0.9726\n",
      "loss function:0.0644315\n",
      "Accuracy:0.9713\n",
      "loss function:0.140348\n",
      "Accuracy:0.9735\n",
      "loss function:0.00216504\n",
      "Accuracy:0.9735\n",
      "loss function:0.0142567\n",
      "Accuracy:0.9707\n",
      "loss function:0.0114741\n",
      "Accuracy:0.9707\n",
      "loss function:0.034758\n",
      "Accuracy:0.973\n",
      "loss function:0.0408259\n",
      "Accuracy:0.9672\n",
      "loss function:0.00545372\n",
      "Accuracy:0.972\n",
      "loss function:0.0166156\n",
      "Accuracy:0.969\n",
      "loss function:0.00841435\n",
      "Accuracy:0.973\n",
      "loss function:0.000646432\n",
      "Accuracy:0.9726\n",
      "loss function:0.00938713\n",
      "Accuracy:0.9728\n",
      "loss function:0.0496866\n",
      "Accuracy:0.9695\n",
      "loss function:0.0166175\n",
      "Accuracy:0.9741\n",
      "loss function:0.000596324\n",
      "Accuracy:0.97\n",
      "loss function:0.000322344\n",
      "Accuracy:0.9732\n",
      "loss function:0.0185583\n",
      "Accuracy:0.9722\n",
      "loss function:0.0325156\n",
      "Accuracy:0.9753\n",
      "loss function:0.0133358\n",
      "Accuracy:0.9712\n",
      "loss function:0.0147883\n",
      "Accuracy:0.9748\n",
      "loss function:0.00395883\n",
      "Accuracy:0.973\n",
      "loss function:0.0401095\n",
      "Accuracy:0.9682\n",
      "loss function:0.0276376\n",
      "Accuracy:0.973\n",
      "loss function:0.00390094\n",
      "Accuracy:0.975\n",
      "loss function:0.00289073\n",
      "Accuracy:0.9734\n",
      "loss function:0.00602666\n",
      "Accuracy:0.9734\n",
      "loss function:0.020112\n",
      "Accuracy:0.971\n",
      "loss function:0.00241317\n",
      "Accuracy:0.9736\n",
      "loss function:0.00308181\n",
      "Accuracy:0.9708\n",
      "loss function:0.0027715\n",
      "Accuracy:0.9717\n",
      "loss function:0.00832281\n",
      "Accuracy:0.9716\n",
      "loss function:0.000617432\n",
      "Accuracy:0.973\n",
      "loss function:0.0116627\n",
      "Accuracy:0.975\n",
      "loss function:0.00456929\n",
      "Accuracy:0.9744\n",
      "loss function:0.00249066\n",
      "Accuracy:0.9749\n",
      "loss function:0.00740846\n",
      "Accuracy:0.9732\n",
      "loss function:0.000437489\n",
      "Accuracy:0.9706\n",
      "loss function:0.00936485\n",
      "Accuracy:0.9732\n",
      "loss function:0.0104226\n",
      "Accuracy:0.9743\n",
      "loss function:0.103662\n",
      "Accuracy:0.9715\n",
      "loss function:0.00689344\n",
      "Accuracy:0.9718\n",
      "loss function:0.0595378\n",
      "Accuracy:0.9702\n",
      "loss function:0.0041454\n",
      "Accuracy:0.9718\n",
      "loss function:0.000870917\n",
      "Accuracy:0.9738\n",
      "loss function:0.000638266\n",
      "Accuracy:0.9698\n",
      "loss function:0.00977486\n",
      "Accuracy:0.9751\n",
      "loss function:0.000570378\n",
      "Accuracy:0.9727\n",
      "loss function:0.000110688\n",
      "Accuracy:0.9719\n",
      "loss function:0.00958652\n",
      "Accuracy:0.9742\n",
      "loss function:1.10501e-05\n",
      "Accuracy:0.9741\n",
      "loss function:0.00393215\n",
      "Accuracy:0.9718\n",
      "loss function:0.0297431\n",
      "Accuracy:0.9742\n",
      "loss function:0.0049116\n",
      "Accuracy:0.9769\n",
      "loss function:0.00256798\n",
      "Accuracy:0.9731\n",
      "loss function:0.00975464\n",
      "Accuracy:0.9744\n",
      "loss function:0.0385952\n",
      "Accuracy:0.9723\n",
      "loss function:0.0200514\n",
      "Accuracy:0.9749\n",
      "loss function:5.37875e-05\n",
      "Accuracy:0.9711\n",
      "loss function:0.00625577\n",
      "Accuracy:0.974\n",
      "loss function:0.00138845\n",
      "Accuracy:0.9709\n",
      "loss function:0.0614684\n",
      "Accuracy:0.974\n",
      "loss function:0.0019213\n",
      "Accuracy:0.9729\n",
      "loss function:0.00532742\n",
      "Accuracy:0.9733\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
