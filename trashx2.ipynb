{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', './data',\n",
    "    \"\"\"Directory of stored data.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size',1,\n",
    "    \"\"\"Size of batch\"\"\")               \n",
    "tf.app.flags.DEFINE_integer('patch_size',128,\n",
    "    \"\"\"Size of a data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('patch_layer',128,\n",
    "    \"\"\"Number of layers in data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('epochs',2000,\n",
    "    \"\"\"Number of epochs for training\"\"\")\n",
    "tf.app.flags.DEFINE_string('log_dir', './tmp/log',\n",
    "    \"\"\"Directory where to write training and testing event logs \"\"\")\n",
    "tf.app.flags.DEFINE_float('init_learning_rate',0.0001,\n",
    "    \"\"\"Initial learning rate\"\"\")\n",
    "tf.app.flags.DEFINE_float('decay_factor',0.01,\n",
    "    \"\"\"Exponential decay learning rate factor\"\"\")\n",
    "tf.app.flags.DEFINE_integer('decay_steps',100,\n",
    "    \"\"\"Number of epoch before applying one learning rate decay\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step',10,\n",
    "    \"\"\"Display and logging interval (train steps)\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_interval',1,\n",
    "    \"\"\"Checkpoint save interval (epochs)\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './tmp/ckpt',\n",
    "    \"\"\"Directory where to write checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_dir','./tmp/model',\n",
    "    \"\"\"Directory to save model\"\"\")\n",
    "tf.app.flags.DEFINE_bool('restore_training',True,\n",
    "    \"\"\"Restore training from last checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_float('drop_ratio',0.9,\n",
    "    \"\"\"Probability to drop a cropped area if the label is empty. All empty patches will be droped for 0 and accept all cropped patches if set to 1\"\"\")\n",
    "tf.app.flags.DEFINE_integer('min_pixel',10,\n",
    "    \"\"\"Minimum non-zero pixels in the cropped label\"\"\")\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size',5,\n",
    "    \"\"\"Number of elements used in shuffle buffer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define 2d basic network structure\n",
    "# tensorflow app flags\n",
    "\n",
    "def init_uniform_dist_2d(shape):\n",
    "    with tf.variable_scope('uniform_dist_initializer'):\n",
    "        denominator = tf.cast((tf.reduce_prod(shape[:2]) * tf.reduce_sum(shape[2:])), tf.float32)\n",
    "        lim = tf.sqrt(6. / denominator)\n",
    "        return tf.random_uniform(shape, minval=-lim, maxval=lim)\n",
    "\n",
    "def init_uniform_dist(shape):\n",
    "    with tf.variable_scope('uniform_dist_initializer'):\n",
    "        denominator = tf.cast((tf.reduce_prod(shape)), tf.float32)\n",
    "        lim = tf.sqrt(6. / denominator)\n",
    "        return tf.random_uniform(shape, minval=-lim, maxval=lim)    \n",
    "    \n",
    "def convolution_2d(layer_input, filter, strides, padding='VALID'):\n",
    "    assert len(filter) == 4  # [filter_height, filter_width, in_channels, out_channels]\n",
    "    assert len(strides) == 4  # must match input dimensions [batch, in_height, in_width, in_channels]\n",
    "    assert padding in ['VALID', 'SAME']\n",
    "\n",
    "    w = tf.Variable(initial_value=init_uniform_dist_2d(shape=filter), name='weights')\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[filter[-1]]), name='biases')\n",
    "\n",
    "    return tf.nn.conv2d(layer_input, w, strides, padding) + b\n",
    "\n",
    "def convolution_block_2d(layer_input, n_channels, out_channel,num_convolutions=1):\n",
    "    x = layer_input\n",
    "    for i in range(num_convolutions - 1):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution_2d(x, [5, 5, n_channels, n_channels], [1, 1, 1, 1])\n",
    "            x = tf.nn.relu(x)\n",
    "    x = convolution_2d(x, [5, 5, n_channels, out_channel], [1, 1, 1, 1])\n",
    "    x = x\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def fc_2d(layer_input, in_channel, out_channel):\n",
    "    x = tf.reshape(layer_input,[-1,in_channel])\n",
    "    w = tf.Variable(initial_value=init_uniform_dist([in_channel,out_channel]), name='weights')# shape unknown issue\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[out_channel]), name='biases')\n",
    "    return tf.nn.relu(tf.matmul(x,w)+b)\n",
    "    \n",
    "def readout_2d(layer_input, in_channel, out_channel):\n",
    "    x = tf.reshape(layer_input,[-1,in_channel])\n",
    "    w = tf.Variable(initial_value=init_uniform_dist([in_channel,out_channel]), name='weights')# shape unknown issue\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[out_channel]), name='biases')\n",
    "    return tf.matmul(x,w)+b\n",
    "    \n",
    "def Net(input,shape, n_channel=16, out_channel=10):\n",
    "    x = tf.reshape(input,[-1,shape[0],shape[1]])\n",
    "    x = tf.tile(x[:,:,:,None],[1,1,1,n_channel])\n",
    "    \n",
    "    N = 0\n",
    "    for i in range(N):\n",
    "        with tf.variable_scope('conv_net_'+str(i)):\n",
    "            x = convolution_block_2d(x,n_channel*(i+1),n_channel*(i+2))\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x,[-1,(shape[0]-4*N)*(shape[1]-4*N)*(N+1)*n_channel])\n",
    "    with tf.variable_scope('fc_0'):\n",
    "        x = fc_2d(x, (shape[0]-4*N)*(shape[1]-4*N)*(N+1)*n_channel, 64)\n",
    "        \n",
    "    with tf.variable_scope('readout'):\n",
    "        x = readout_2d(x, 64, out_channel)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    shape = [28,28]\n",
    "    x = tf.placeholder(tf.float32, [None,28*28])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    y = Net(x,shape)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for iter in range(10):\n",
    "        for i in range(2000):\n",
    "            batch = mnist.train.next_batch(50)\n",
    "            sess.run(train_step,feed_dict={x: batch[0], y_: batch[1]})\n",
    "            \n",
    "            if i % 200 is 0:\n",
    "                loss = sess.run(cross_entropy,feed_dict={x: batch[0], y_: batch[1]})\n",
    "                print(\"loss function:%g\"%loss)\n",
    "                print(\"Accuracy:%g\"%sess.run(accuracy,feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "if 1 is  1:\n",
    "    print('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1]+[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
