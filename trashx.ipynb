{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuchengzhu/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/xuchengzhu/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from DL_app import tf_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "flags.DEFINE_integer('num_classes', 10, 'the number of classes')\n",
    "flags.DEFINE_float('dropout_rate', .95, 'the dropout rate of the CNN')\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN layer definition\n",
    "\n",
    "def xavier_normal_dist_conv3d(shape):\n",
    "    return tf.truncated_normal(shape, mean=0,\n",
    "                               stddev=tf.sqrt(3. / (tf.reduce_prod(shape[:3]) * tf.reduce_sum(shape[3:]))))\n",
    "\n",
    "def xavier_uniform_dist_conv3d(shape):\n",
    "    with tf.variable_scope('xavier_glorot_initializer'):\n",
    "        denominator = tf.cast((tf.reduce_prod(shape[:3]) * tf.reduce_sum(shape[3:])), tf.float32)\n",
    "        lim = tf.sqrt(6. / denominator)\n",
    "        return tf.random_uniform(shape, minval=-lim, maxval=lim)\n",
    "\n",
    "def convolution_3d(layer_input, filter, strides, padding='SAME'):\n",
    "    assert len(filter) == 5  # [filter_depth, filter_height, filter_width, in_channels, out_channels]\n",
    "    assert len(strides) == 5  # must match input dimensions [batch, in_depth, in_height, in_width, in_channels]\n",
    "    assert padding in ['VALID', 'SAME']\n",
    "\n",
    "    w = tf.Variable(initial_value=xavier_uniform_dist_conv3d(shape=filter), name='weights')\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[filter[-1]]), name='biases')\n",
    "\n",
    "    return tf.nn.conv3d(layer_input, w, strides, padding) + b\n",
    "\n",
    "\n",
    "def deconvolution_3d(layer_input, filter, output_shape, strides, padding='SAME'):\n",
    "    assert len(filter) == 5  # [depth, height, width, output_channels, in_channels]\n",
    "    assert len(strides) == 5  # must match input dimensions [batch, depth, height, width, in_channels]\n",
    "    assert padding in ['VALID', 'SAME']\n",
    "\n",
    "    w = tf.Variable(initial_value=xavier_uniform_dist_conv3d(shape=filter), name='weights')\n",
    "    b = tf.Variable(tf.constant(1.0, shape=[filter[-2]]), name='biases')\n",
    "\n",
    "    return tf.nn.conv3d_transpose(layer_input, w, output_shape, strides, padding) + b\n",
    "\n",
    "\n",
    "\n",
    "def CNN3d_layer(input, output_size, scope, activation_function=tf.tanh):\n",
    "    with tf.variable_scope(scope):\n",
    "        W = tf.get_variable('weight', shape=(1, input.shape[1].value, FLAGS.num_classes, input.shape[-2].value, 16),\n",
    "                        dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=FLAGS.stddev))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_block(layer_input, n_channels, num_convolutions):\n",
    "    x = layer_input\n",
    "    for i in range(num_convolutions - 1):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution_3d(x, [5, 5, 5, n_channels, n_channels], [1, 1, 1, 1, 1])\n",
    "            x = prelu(x)\n",
    "    x = convolution_3d(x, [5, 5, 5, n_channels, n_channels], [1, 1, 1, 1, 1])\n",
    "    x = x + layer_input\n",
    "    return prelu(x)\n",
    "\n",
    "def convolution_block_2(layer_input, fine_grained_features, n_channels, num_convolutions):\n",
    "\n",
    "    x = tf.concat((layer_input, fine_grained_features), axis=-1)\n",
    "\n",
    "    with tf.variable_scope('conv_' + str(1)):\n",
    "        x = convolution_3d(x, [5, 5, 5, n_channels * 2, n_channels], [1, 1, 1, 1, 1])\n",
    "\n",
    "    for i in range(1, num_convolutions - 1):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution_3d(x, [5, 5, 5, n_channels, n_channels], [1, 1, 1, 1, 1])\n",
    "            x = prelu(x)\n",
    "\n",
    "    x = convolution_3d(x, [5, 5, 5, n_channels, n_channels], [1, 1, 1, 1, 1])\n",
    "    x = x + layer_input\n",
    "    return prelu(x)\n",
    "\n",
    "\n",
    "def down_convolution(layer_input, in_channels):\n",
    "    with tf.variable_scope('down_convolution'):\n",
    "        x = convolution_3d(layer_input, [2, 2, 2, in_channels, in_channels * 2], [1, 2, 2, 2, 1])\n",
    "        return prelu(x)\n",
    "\n",
    "\n",
    "def up_convolution(layer_input, output_shape, in_channels):\n",
    "    with tf.variable_scope('up_convolution'):\n",
    "        x = deconvolution_3d(layer_input, [2, 2, 2, in_channels // 2, in_channels], output_shape, [1, 2, 2, 2, 1])\n",
    "        return prelu(x)\n",
    "    \n",
    "def v_net(tf_input, input_channels, output_channels=1, n_channels=16):\n",
    "\n",
    "    with tf.variable_scope('contracting_path'):\n",
    "\n",
    "        # if the input has more than 1 channel it has to be expanded because broadcasting only works for 1 input channel\n",
    "        if input_channels == 1:\n",
    "            c0 = tf.tile(tf_input, [1, 1, 1, 1, n_channels])\n",
    "        else:\n",
    "            with tf.variable_scope('level_0'):\n",
    "                c0 = prelu(convolution_3d(tf_input, [5, 5, 5, input_channels, n_channels], [1, 1, 1, 1, 1]))\n",
    "\n",
    "        with tf.variable_scope('level_1'):\n",
    "            c1 = convolution_block(c0, n_channels, 1)\n",
    "            c12 = down_convolution(c1, n_channels)\n",
    "\n",
    "        with tf.variable_scope('level_2'):\n",
    "            c2 = convolution_block(c12, n_channels * 2, 2)\n",
    "            c22 = down_convolution(c2, n_channels * 2)\n",
    "\n",
    "        with tf.variable_scope('level_3'):\n",
    "            c3 = convolution_block(c22, n_channels * 4, 3)\n",
    "            c32 = down_convolution(c3, n_channels * 4)\n",
    "\n",
    "        with tf.variable_scope('level_4'):\n",
    "            c4 = convolution_block(c32, n_channels * 8, 3)\n",
    "            c42 = down_convolution(c4, n_channels * 8)\n",
    "\n",
    "        with tf.variable_scope('level_5'):\n",
    "            c5 = convolution_block(c42, n_channels * 16, 3)\n",
    "            c52 = up_convolution(c5, tf.shape(c4), n_channels * 16)\n",
    "\n",
    "    with tf.variable_scope('expanding_path'):\n",
    "\n",
    "        with tf.variable_scope('level_4'):\n",
    "            e4 = concat_layer(c52, c4, 3)\n",
    "            e42 = up_convolution(e4, tf.shape(c3), n_channels * 8)\n",
    "\n",
    "        with tf.variable_scope('level_3'):\n",
    "            e3 = convolution_block_2(e42, c3, n_channels * 4, 3)\n",
    "            e32 = up_convolution(e3, tf.shape(c2), n_channels * 4)\n",
    "\n",
    "        with tf.variable_scope('level_2'):\n",
    "            e2 = convolution_block_2(e32, c2, n_channels * 2, 2)\n",
    "            e22 = up_convolution(e2, tf.shape(c1), n_channels * 2)\n",
    "\n",
    "        with tf.variable_scope('level_1'):\n",
    "            e1 = convolution_block_2(e22, c1, n_channels, 1)\n",
    "            with tf.variable_scope('output_layer'):\n",
    "                logits = convolution_3d(e1, [1, 1, 1, n_channels, output_channels], [1, 1, 1, 1, 1])\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(input_batch_shape, output_batch_shape):\n",
    "    \"\"\"Generate placeholder variables to represent the the input tensors.\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded ckpt in the .run() loop, below.\n",
    "    Args:\n",
    "        patch_shape: The patch_shape will be baked into both placeholders.\n",
    "    Returns:\n",
    "        images_placeholder: Images placeholder.\n",
    "        labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test ckpt sets.\n",
    "    # batch_size = -1\n",
    "\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=input_batch_shape, name=\"images_placeholder\")\n",
    "    labels_placeholder = tf.placeholder(tf.float32, shape=output_batch_shape, name=\"labels_placeholder\")   \n",
    "   \n",
    "    return images_placeholder, labels_placeholder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# tensorflow app flags\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', './data',\n",
    "    \"\"\"Directory of stored data.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size',1,\n",
    "    \"\"\"Size of batch\"\"\")               \n",
    "tf.app.flags.DEFINE_integer('patch_size',128,\n",
    "    \"\"\"Size of a data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('patch_layer',128,\n",
    "    \"\"\"Number of layers in data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('epochs',2000,\n",
    "    \"\"\"Number of epochs for training\"\"\")\n",
    "tf.app.flags.DEFINE_string('log_dir', './tmp/log',\n",
    "    \"\"\"Directory where to write training and testing event logs \"\"\")\n",
    "tf.app.flags.DEFINE_float('init_learning_rate',0.0001,\n",
    "    \"\"\"Initial learning rate\"\"\")\n",
    "tf.app.flags.DEFINE_float('decay_factor',0.01,\n",
    "    \"\"\"Exponential decay learning rate factor\"\"\")\n",
    "tf.app.flags.DEFINE_integer('decay_steps',100,\n",
    "    \"\"\"Number of epoch before applying one learning rate decay\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step',10,\n",
    "    \"\"\"Display and logging interval (train steps)\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_interval',1,\n",
    "    \"\"\"Checkpoint save interval (epochs)\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './tmp/ckpt',\n",
    "    \"\"\"Directory where to write checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_dir','./tmp/model',\n",
    "    \"\"\"Directory to save model\"\"\")\n",
    "tf.app.flags.DEFINE_bool('restore_training',True,\n",
    "    \"\"\"Restore training from last checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_float('drop_ratio',0.5,\n",
    "    \"\"\"Probability to drop a cropped area if the label is empty. All empty patches will be droped for 0 and accept all cropped patches if set to 1\"\"\")\n",
    "tf.app.flags.DEFINE_integer('min_pixel',10,\n",
    "    \"\"\"Minimum non-zero pixels in the cropped label\"\"\")\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size',5,\n",
    "    \"\"\"Number of elements used in shuffle buffer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Train the Vnet model\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        # patch_shape(batch_size, height, width, depth, channels)\n",
    "        input_batch_shape = (FLAGS.batch_size, FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer, 1) \n",
    "        output_batch_shape = (FLAGS.batch_size, FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer, 1) \n",
    "        \n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(input_batch_shape,output_batch_shape)\n",
    "\n",
    "        images_log = tf.cast(images_placeholder[:,:,:,int(FLAGS.patch_layer/2),:], dtype=tf.uint8)\n",
    "        labels_log = tf.cast(tf.scalar_mul(255,labels_placeholder[:,:,:,int(FLAGS.patch_layer/2),:]), dtype=tf.uint8)\n",
    "\n",
    "        tf.summary.image(\"image\", images_log,max_outputs=FLAGS.batch_size)\n",
    "        tf.summary.image(\"label\", labels_log,max_outputs=FLAGS.batch_size)\n",
    "\n",
    "        # Get images and labels\n",
    "        train_data_dir = os.path.join(FLAGS.data_dir,'training')\n",
    "        test_data_dir = os.path.join(FLAGS.data_dir,'testing')\n",
    "        # support multiple image input, but here only use single channel, label file should be a single file with different classes\n",
    "        image_filename = 'img.nii.gz'\n",
    "        label_filename = 'label.nii.gz'\n",
    "\n",
    "        # Force input pipepline to CPU:0 to avoid operations sometimes ended up at GPU and resulting a slow down\n",
    "        with tf.device('/cpu:0'):\n",
    "            # create transformations to image and labels\n",
    "            trainTransforms = [\n",
    "                NiftiDataset.Normalization(),\n",
    "                NiftiDataset.Resample(0.4356),\n",
    "                NiftiDataset.Padding((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer)),\n",
    "                NiftiDataset.RandomCrop((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer),FLAGS.drop_ratio,FLAGS.min_pixel),\n",
    "                NiftiDataset.RandomNoise()\n",
    "                ]\n",
    "\n",
    "            TrainDataset = NiftiDataset.NiftiDataset(\n",
    "                data_dir=train_data_dir,\n",
    "                image_filename=image_filename,\n",
    "                label_filename=label_filename,\n",
    "                transforms=trainTransforms,\n",
    "                train=True\n",
    "                )\n",
    "            \n",
    "            trainDataset = TrainDataset.get_dataset()\n",
    "            trainDataset = trainDataset.shuffle(buffer_size=5)\n",
    "            trainDataset = trainDataset.batch(FLAGS.batch_size)\n",
    "\n",
    "            testTransforms = [\n",
    "                NiftiDataset.Normalization(),\n",
    "                NiftiDataset.Resample(0.4356),\n",
    "                NiftiDataset.Padding((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer)),\n",
    "                NiftiDataset.RandomCrop((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer),FLAGS.drop_ratio,FLAGS.min_pixel)\n",
    "                ]\n",
    "\n",
    "            TestDataset = NiftiDataset.NiftiDataset(\n",
    "                data_dir=train_data_dir,\n",
    "                image_filename=image_filename,\n",
    "                label_filename=label_filename,\n",
    "                transforms=testTransforms,\n",
    "                train=True\n",
    "            )\n",
    "\n",
    "            testDataset = TestDataset.get_dataset()\n",
    "            testDataset = testDataset.shuffle(buffer_size=5)\n",
    "            testDataset = testDataset.batch(FLAGS.batch_size)\n",
    "            \n",
    "        train_iterator = trainDataset.make_initializable_iterator()\n",
    "        next_element_train = train_iterator.get_next()\n",
    "\n",
    "        test_iterator = testDataset.make_initializable_iterator()\n",
    "        next_element_test = test_iterator.get_next()\n",
    "\n",
    "        # Initialize the model\n",
    "        with tf.name_scope(\"vnet\"):\n",
    "            logits = VNet.v_net(images_placeholder,input_channels = input_batch_shape[4], output_channels =2)\n",
    "\n",
    "        logits_log_0 = tf.cast(logits[:,:,:,int(FLAGS.patch_layer/2):int(FLAGS.patch_layer/2)+1,0], dtype=tf.uint8)\n",
    "        logits_log_1 = tf.cast(logits[:,:,:,int(FLAGS.patch_layer/2):int(FLAGS.patch_layer/2)+1,1], dtype=tf.uint8)\n",
    "        tf.summary.image(\"logits_0\", logits_log_0,max_outputs=FLAGS.batch_size)\n",
    "        tf.summary.image(\"logits_1\", logits_log_1,max_outputs=FLAGS.batch_size)\n",
    "\n",
    "        # # Exponential decay learning rate\n",
    "        # train_batches_per_epoch = math.ceil(TrainDataset.data_size/FLAGS.batch_size)\n",
    "        # decay_steps = train_batches_per_epoch*FLAGS.decay_steps\n",
    "\n",
    "        with tf.name_scope(\"learning_rate\"):\n",
    "            learning_rate = FLAGS.init_learning_rate\n",
    "        #     learning_rate = tf.train.exponential_decay(FLAGS.init_learning_rate,\n",
    "        #         global_step,\n",
    "        #         decay_steps,\n",
    "        #         FLAGS.decay_factor,\n",
    "        #         staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "        # softmax op for probability layer\n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            softmax_op = tf.nn.softmax(logits,name=\"softmax\")\n",
    "        softmax_log_0 = tf.cast(tf.scalar_mul(255,softmax_op[:,:,:,int(FLAGS.patch_layer/2):int(FLAGS.patch_layer/2)+1,0]), dtype=tf.uint8)\n",
    "        softmax_log_1 = tf.cast(tf.scalar_mul(255,softmax_op[:,:,:,int(FLAGS.patch_layer/2):int(FLAGS.patch_layer/2)+1,1]), dtype=tf.uint8)\n",
    "\n",
    "        tf.summary.image(\"softmax_0\", softmax_log_0,max_outputs=FLAGS.batch_size)\n",
    "        tf.summary.image(\"softmax_1\", softmax_log_1,max_outputs=FLAGS.batch_size)\n",
    "\n",
    "        # Op for calculating loss\n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=logits,\n",
    "                labels=tf.squeeze(labels_placeholder, \n",
    "                squeeze_dims=[4])))\n",
    "        tf.summary.scalar('loss',loss_op)\n",
    "\n",
    "        # Argmax Op to generate label from logits\n",
    "        with tf.name_scope(\"predicted_label\"):\n",
    "            pred = tf.argmax(logits, axis=4 , name=\"prediction\")\n",
    "        pred_log = tf.cast(tf.scalar_mul(255,pred[:,:,:,int(FLAGS.patch_layer/2):int(FLAGS.patch_layer/2)+1]), dtype=tf.uint8)\n",
    "        tf.summary.image(\"pred\", pred_log,max_outputs=FLAGS.batch_size)\n",
    "\n",
    "        # Training Op\n",
    "        with tf.name_scope(\"training\"):\n",
    "            # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=FLAGS.init_learning_rate)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss_op,\n",
    "                global_step=global_step)\n",
    "\n",
    "        # Accuracy of model\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_pred = tf.equal(tf.expand_dims(pred,-1), tf.cast(labels_placeholder,dtype=tf.int64))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Dice Similarity\n",
    "        with tf.name_scope(\"dice\"):\n",
    "            sorensen = dice_coe(tf.expand_dims(pred,-1),tf.cast(labels_placeholder,dtype=tf.int64), loss_type='sorensen')\n",
    "            jaccard = dice_coe(tf.expand_dims(pred,-1),tf.cast(labels_placeholder,dtype=tf.int64), loss_type='jaccard')\n",
    "        tf.summary.scalar('sorensen', sorensen)\n",
    "        tf.summary.scalar('jaccard', jaccard)\n",
    "\n",
    "        # # epoch checkpoint manipulation\n",
    "        start_epoch = tf.get_variable(\"start_epoch\", shape=[1], initializer= tf.zeros_initializer,dtype=tf.int32)\n",
    "        start_epoch_inc = start_epoch.assign(start_epoch+1)\n",
    "\n",
    "        # # save model builder\n",
    "        # builder = tf.saved_model.builder.SavedModelBuilder(FLAGS.checkpoint_dir)\n",
    "\n",
    "\n",
    "        # saver\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        checkpoint_prefix = os.path.join(FLAGS.checkpoint_dir ,\"checkpoint\")\n",
    "        print(\"Setting up Saver...\")\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # training cycle\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"{}: Start training...\".format(datetime.datetime.now()))\n",
    "\n",
    "            # summary writer for tensorboard\n",
    "            train_summary_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\n",
    "            test_summary_writer = tf.summary.FileWriter(FLAGS.log_dir + '/test', sess.graph)\n",
    "\n",
    "            # restore from checkpoint\n",
    "            if FLAGS.restore_training:\n",
    "                # check if checkpoint exists\n",
    "                if os.path.exists(checkpoint_prefix+\"-latest\"):\n",
    "                    print(\"{}: Last checkpoint found at {}, loading...\".format(datetime.datetime.now(),FLAGS.checkpoint_dir))\n",
    "                    latest_checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_dir,latest_filename=\"checkpoint-latest\")\n",
    "                    saver.restore(sess, latest_checkpoint_path)\n",
    "            \n",
    "            print(\"{}: Last checkpoint epoch: {}\".format(datetime.datetime.now(),start_epoch.eval()[0]))\n",
    "            print(\"{}: Last checkpoint global step: {}\".format(datetime.datetime.now(),tf.train.global_step(sess, global_step)))\n",
    "\n",
    "            # loop over epochs\n",
    "            for epoch in np.arange(start_epoch.eval(), FLAGS.epochs):\n",
    "                # initialize iterator in each new epoch\n",
    "                sess.run(train_iterator.initializer)\n",
    "                sess.run(test_iterator.initializer)\n",
    "                print(\"{}: Epoch {} starts\".format(datetime.datetime.now(),epoch+1))\n",
    "\n",
    "                # training phase\n",
    "                while True:\n",
    "                    try:\n",
    "                        [image, label] = sess.run(next_element_train)\n",
    "\n",
    "                        image = image[:,:,:,:,np.newaxis]\n",
    "                        label = label[:,:,:,:,np.newaxis]\n",
    "                        \n",
    "                        train, summary = sess.run([train_op, summary_op], feed_dict={images_placeholder: image, labels_placeholder: label})\n",
    "                        train_summary_writer.add_summary(summary, global_step=tf.train.global_step(sess, global_step))\n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        start_epoch_inc.op.run()\n",
    "                        # print(start_epoch.eval())\n",
    "                        # save the model at end of each epoch training\n",
    "                        print(\"{}: Saving checkpoint of epoch {} at {}...\".format(datetime.datetime.now(),epoch+1,FLAGS.checkpoint_dir))\n",
    "                        saver.save(sess, checkpoint_prefix, \n",
    "                            global_step=tf.train.global_step(sess, global_step),\n",
    "                            latest_filename=\"checkpoint-latest\")\n",
    "                        print(\"{}: Saving checkpoint succeed\".format(datetime.datetime.now()))\n",
    "                        break\n",
    "                \n",
    "                # testing phase\n",
    "                print(\"{}: Training of epoch {} finishes, testing start\".format(datetime.datetime.now(),epoch+1))\n",
    "                while True:\n",
    "                    try:\n",
    "                        [image, label] = sess.run(next_element_test)\n",
    "\n",
    "                        image = image[:,:,:,:,np.newaxis]\n",
    "                        label = label[:,:,:,:,np.newaxis]\n",
    "                        \n",
    "                        loss, summary = sess.run([loss_op, summary_op], feed_dict={images_placeholder: image, labels_placeholder: label})\n",
    "                        test_summary_writer.add_summary(summary, global_step=tf.train.global_step(sess, global_step))\n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        break\n",
    "\n",
    "        # close tensorboard summary writer\n",
    "        train_summary_writer.close()\n",
    "        test_summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
